---
title: Using Edge Services Gateway on VMware NSX
owner: Customer0
---

This topic describes how to configure the NSX firewall, load balancing, and NAT/SNAT services for <%= vars.ops_manager %> on vSphere installations. These NSX-provided services take the place of an external device or the bundled HAProxy VM in <%= vars.app_runtime_full %> (<%= vars.app_runtime_abbr %>).

This document presents the reader with fundamental configuration options of an Edge Services Gateway (ESG) with <%= vars.ops_manager %> and vSphere NSX. Its purpose is not to dictate the settings required on every deployment, but instead to empower the NSX Administrator with the ability to establish a known good "base" configuration and apply specific security configurations as required.

If you are using NSX, the specific configurations described here supersede any general recommendations in [Preparing Your Firewall](../../install/config_firewall.html).


## <a id="assumptions"></a> Assumptions

This topic assumes that the reader has the level of skill required to install and configure these products:

*	VMware vSphere v5.5 or later
*	NSX v6.1.x or later
*	<%= vars.ops_manager %> v1.6 or later

For detailed installation and configuration information about these products, see:

* The	[vSphere documentation](https://www.vmware.com/support/pubs/vsphere-esxi-vcenter-server-pubs.html)

*	[NSX Installation and Upgrade Guide](https://pubs.vmware.com/NSX-6/topic/com.vmware.ICbase/PDF/nsx_6_install.pdf)

*	[Reference Design: VMware NSX for vSphere (NSX) Network Virtualization Design Guide](https://www.vmware.com/files/pdf/products/nsx/vmw-nsx-network-virtualization-design-guide.pdf)

* [Installation Overview](../../install/index.html)


## <a id="overview"></a> General Overview

This cookbook follows a three-step recipe to deploy <%= vars.ops_manager %>, <%= vars.app_runtime_abbr %> and services behind an ESG:

1. [Configure Firewall](#firewall)
1. [Configure Load Balancer](#load_balancer)
1. [Configure NAT/SNAT](#nat_snat)

The ESG can scale to accommodate very large deployments as needed.

This cookbook focuses on a single-site deployment and makes these design assumptions:

*	There are five non-routable networks on the tenant (inside) side of the ESG.
   * The **infra** network is used to deploy <%= vars.ops_manager %> and BOSH Director.
   * The **deployment** network is used exclusively by <%= vars.app_runtime_abbr %> to deploy Diego Cells that host apps and related elements.
   * The **tiles** network is used for all other deployed tiles in an <%= vars.ops_manager %> installation.
   * The **services** network is used by BOSH Director for service tiles.
   * The **container-to-container** network is used for container to container communication in the Diego Cells.

*	There is a single service provider (outside) interface on the ESG that provides firewall, load balancing, and NAT/SNAT services.

* The service provider (outside) interface is connected appropriately to the network backbone of the environment, as either routed or non-routed depending on the design. This cookbook does not cover provisioning of the uplink interface.

*	Routable IP addresses should be applied to the service provider (outside) interface of the ESG. <%= vars.company_name %> recommends that you apply 10 consecutive routable IP addresses to each ESG:
  *	One reserved for NSX use (Controller to Edge I/F)
  *	One for NSX Load Balancer to Gorouters
  * One for NSX Load Balancer to Diego Brains for SSH to apps
  *	One routable IP address, used to access the <%= vars.ops_manager %> front end
  *	One routable IP address, used with SNAT egress
  *	Five for future use

<%= vars.company_name %> recommends that operators deploy the ESGs as high availability (HA) pairs in vSphere. <%= vars.company_name %> also recommends that they be sized "large" or greater for any pre-production or production use. The deployed size of the ESG impacts its overall performance, including how many SSL tunnels it can terminate.

The ESGs have an interface in each port group used by the foundation as well as a port group on the service provider (outside), often called the "transit network". Each installation has a set of port groups in a vSphere DVS to support connectivity, so that the ESG arrangement is repeated for every install. It is not necessary to build a DVS for each ESG/foundation. You do not re-use an ESG amongst deployments. NSX Logical Switches (VXLAN vWires) are ideal candidates for use with this architecture.

The diagram below illustrates an example of port groups used with an ESG:

<%= image_tag('images/vsphere-port-groups.png', :alt => "Complex diagram. For more information, see other sections.") %>

[View a larger version of this diagram](../images/vsphere-port-groups.png).

The diagram below illustrates an example of a network architecture deployment.

<%= image_tag('images/vsphere-overview-arch.png', :alt => "Complex diagram. For more information, see other sections.") %>

[View a larger version of this diagram](../images/vsphere-overview-arch.png).

The diagram below illustrates container-to-container networking. The overlay addresses are wrapped and transported using the underlay deployment subnet.

<%= image_tag('images/vsphere-pcf-c2c-networking.png', :alt => "Complex diagram. For more information, see other sections.") %>

[View a larger version of this diagram](../images/vsphere-pcf-c2c-networking.png).


## <a id="prereq"></a> Prep Step: Configure DNS and Network Prerequisites

As a prerequisite, create wildcard DNS entries for system and apps domains in <%= vars.app_runtime_abbr %>. Map these domains to the selected IP address on the uplink (outside) interface of the ESG in your DNS server.

The wildcard DNS `A` record must resolve to an IP address associated with the outside interface of the ESG for it to function as a load balancer. You can either use a single IP address to resolve both the system and apps domain, or one IP address for each.

Additionally, assign these IP addresses and address ranges within your network:

1.	Assign IP Addresses to the "Uplink" (outside) interface.
  *	Typically, you have one SNAT and three DNATs per ESG.
  *	IP associated for SNAT use: All <%= vars.ops_manager %> internal IP addresses appear to be coming from this IP address at the ESG.
  *	IP associated with <%= vars.ops_manager %> DNAT: This IP address is the publicly routable interface for <%= vars.ops_manager %> UI and SSH access.

1.	Assign "Internal" Interface IP Address Space to the Edge Gateway.
  *	192.168.10.0/26 = <%= vars.ops_manager %> deployment network (logical switch or port group)
  *	192.168.20.0/22 = Deployment network for the <%= vars.app_runtime_abbr %> tile
  *	192.168.24.0/22 = Tiles network for all tiles besides <%= vars.app_runtime_abbr %>
  * 192.168.28.0/22 = Dynamic services network for BOSH Director-managed service tiles.
  * 10.255.0.0/16 = Container-to-container network for intercontainer communication.

You must update the security group and load balancer information for your <%= vars.app_runtime_abbr %> deployments using NSX-V on vSphere through the <%= vars.ops_manager %> API. For more information, see [vSphere with NSX-T or NSX-V](https://docs.pivotal.io/application-service/operating/configure-lb.html#vsphere) in _Configuring Load Balancing for <%= vars.app_runtime_abbr %>_.


## <a id="firewall"></a> Step 1: Configure Firewall

This procedure populates the ESG internal firewall with rules to protect a foundation.

These rules provide granular control on what can be accessed within an installation. For example, rules can be used to allow or deny another installation behind a different ESG access to apps published within the installation you are protecting.

This step is not required for the installation to function properly when the firewall feature is disabled or set to **Allow All**.

To configure the ESG firewall:

1. Select **Edge**.

1. Select **Manage**.

1. Click **Firewall** and set these rules:

    | Name | Source | Destination | Service | Action |
    | ---- | ------ | ----------- | ------- | ------ |
    | Allow Ingress -> <%= vars.ops_manager %> VM | Any | OPS-MANAGER-IP | SSH, HTTP, HTTPS | Accept |
    | Allow Ingress -> <%= vars.app_runtime_abbr %> | Any | NSX-LOAD-BALANCER-IP | HTTP, HTTPS | Accept |
    | Allow Ingress -> SSH for Apps | Any | tcp:DIEGO-BRAIN-IP:2222 | Any | Accept |
    | Allow Ingress -> TCProuter | Any | tcp:NSX-TCP-LOAD-BALANCER-IP:5000 | Any | Accept |
    | Allow Inside <-> Inside (internal component communications)| 192.168.10.0/26 192.168.20.0/22 192.168.24.0/22 192.168.28.0/22 | 192.168.10.0/26 192.168.20.0/22 192.168.24.0/22 192.168.28.0/22 | Any | Accept |
    | Allow Egress -> IaaS | 192.168.10.0/26 | VCENTER-IP ESXI-SVRS-IPS | HTTP, HTTPS | Accept |
    | Allow Egress -> DNS | 192.168.0.0/16 | DNS-IP | DNS, DNS-UDP | Accept |
    | Allow Egress -> NTP | 192.168.0.0/16 | NTP-IP | NTP | Accept |
    | Allow Egress -> SYSLOG | 192.168.0.0/16 | Syslog:514-IP | SYSLOG | Accept |
    | Allow ICMP | 192.168.10.0/26 | \* | ICMP | Accept |
    | Allow Egress -> LDAP | 192.168.10.0/26 192.168.20.0/22 | LDAP:389-IP | LDAP, LDAP-over-ssl | Accept |
    | Allow Egress -> All Outbound | 192.168.0.0/16 | Any | Any | Accept |
    | Default Rule | Any | Any | Any | Deny |


## <a id="load_balancer"></a> Step 2: Configure Load Balancer

The ESG provides software load balancing functionality, equivalent to the bundled HAProxy that is included with <%= vars.app_runtime_abbr %>, or hardware appliances such as an F5 or A10 load balancer.

This step is required for the installation to function properly.

There are seven high-level steps to this procedure:

1. Import SSL certificates to the Edge for SSL termination.

1. Enable the load balancer.

1. Create Application Profiles in the Load Balancing tab of NSX.

1. Create Application Rules in the load balancer.

1. Create Service Monitors for each pool type.

1. Create Application Pools for the multiple groups needing load balancing.

1. Create a Virtual Server (also known as a VIP) to pool-balanced IP addresses.

To do this procedure, you need PEM files of SSL certificates provided by the certificate supplier for only this installation of <%= vars.app_runtime_abbr %>, or the self-signed SSL certificates generated during <%= vars.app_runtime_abbr %> installation.

In this procedure, you combine the ESG's IP address used for load balancing with a series of internal IP addresses provisioned for Gorouters in <%= vars.app_runtime_abbr %>. It is important to know the IP addresses used for the Gorouters beforehand.

You can pre-select or reserved IP addresses prior to deployment. Otherwise, you can discover them after deployment by looking them up in BOSH Director, which lists them in the release information of your <%= vars.app_runtime_abbr %> installation. <%= vars.company_name %> recommends using IP addresses that you pre-select or reserve prior to deployment.

You do all of the procedures in these sections through the ESG UI.

### <a id="import_ssl"></a> Step 2.1: Import SSL Certificate

<%= vars.app_runtime_abbr %> requires SSL termination at the load balancer.

<p class="note"><strong>Note:</strong> If you intend to pass SSL termination through the load balancer directly to the Gorouters, you can skip the step below and select <strong>Enable SSL Passthru</strong> in your <code><%= vars.platform_code %>-HTTP</code> Application Profile.</p>

To enable SSL termination at the load balancer in ESG:

1. Select **Edge**.

1. Click the **Manage** tab.

1. Select **Settings**.

1. Select **Certificates**.

1. Click the green **+** button to add a certificate.

1. Enter the PEM file contents from the **Networking** pane of the <%= vars.app_runtime_abbr %> tile.

1. Click **Save**.

### <a id="enable_lb"></a> Step 2.2: Enable the Load Balancer

To enable the load balancer:

1. Select **Load Balancer**.

1. Select **Global Configuration**.

1. Edit the load balancer global configuration.

1. Enable the load balancer.

1. Enable acceleration.

1. Set logging to your desired level.

### <a id="create_app"></a> Step 2.3: Create Application Profiles

The Application Profiles allow advanced `X-Forwarded` options as well as linking to the SSL certificate. You must create three profiles: `<%= vars.platform_code %>-HTTP`, `<%= vars.platform_code %>-HTTPS`, and `<%= vars.platform_code %>-TCP`.

1. Select **Load Balancer**.

1. Select **Global Application Profiles**.

1. To create the `<%= vars.platform_code %>-HTTP` rule:
  1. Click the green **+** button.
  1. Click the pencil icon to to edit the profile.
  1. In the **Name** field, enter `<%= vars.platform_code %>-HTTP`.
  1. Enable the **Insert X-Forwarded-For HTTP header** checkbox.

    <%= image_tag('images/vsphere-app-profile-pcf-http.png', :alt => "'Edit Profile' screen  shows several fields, including 'Name' and 'Insert X-Forwarded-For HTTP header' enabled.") %>

1. To create the `<%= vars.platform_code %>-HTTPS` rule:
  1. Click the green **+** button.
  1. Click the pencil icon to to edit the profile.
  1. In the **Name** field, enter `<%= vars.platform_code %>-HTTPS`.
  1. Enable the **Insert X-Forwarded-For HTTP header** checkbox.
  1. Enter the service certificate you inserted previously
  1. If encrypting TLS traffic to the Gorouters, select the **Enable Pool Side SSL** checkbox. Otherwise, leave the checkbox deselected.

    <%= image_tag('images/vsphere-app-profile-pcf-https.png', :alt => "'Edit Profile' screen has table filtered by 'Service Certificates' and a cert in a table.") %>

1. To create the `<%= vars.platform_code %>-TCP` rule:
  1. Click the green **+** button.
  1. Click the pencil icon to to edit the profile.
  1. In the **Name** field, enter `<%= vars.platform_code %>-TCP`.
  1. From the **Type** dropdown, select **TCP**.

    <%= image_tag('images/vsphere-app-profile-pcf-tcp.png', :alt => "'Edit Profile' screen has 'Type' dropdown set to TCP.") %>

### <a id="create_app_rules"></a> Step 2.4: Create Application Rules

In order for the ESG to perform proper `X-Forwarded` requests, you must add HAProxy directives to the ESG Application Rules. NSX supports most directives that HAProxy supports.

To create the Application Rules:

1. Select **Load Balancer**.

1. Select **Application Rules**.

1. To create the `option httplog` rule:
  1. Click the green **+** button.
  1. For **Name**, enter `option httplog`.
  1. For **Script**, enter `option httplog`.

1. To create the `reqadd X-Forwarded-Proto:\ https` rule:
  1. Click the green **+** button.
  1. For **Name**, enter `reqadd X-Forwarded-Proto:\ https`.
  1. For **Script**, enter `reqadd X-Forwarded-Proto:\ https`.

1. To create the `reqadd X-Forwarded-Proto:\ http` rule:
  1. Click the green **+** button.
  1. For **Name**, enter `reqadd X-Forwarded-Proto:\ http`.
  1. For **Script**, enter `reqadd X-Forwarded-Proto:\ http`.

<%= image_tag('images/vsphere-lb-app-rules.png', :alt => "'Add Application Rule' modal shows 'Name' and 'Script' text fields filled with the script described in the steps above.") %>

### <a id="create_monitors"></a> Step 2.5: Create Monitors For Pools

NSX ships with several load balancing monitoring types pre-defined. These types are for HTTP, HTTPS, and TCP. For this installation, operators build new monitors matching the needs of each pool to ensure correct 1:1 monitoring for each pool type.

To create monitors for pools:

1. Select **Load Balancer**.

1. Select **Service Monitoring**.

1. To create a new monitor for `http-routers`:
  1. Click the green **+** button. Keep all defaults.
  1. For **Name**, enter `http-routers`.
  1. From the **Type** dropdown, select **HTTP**.
  1. From the **Method** dropdown, select **GET**.
  1. From the **URL** dropdown, select **/health**.

1. To create a new monitor for `tcp-routers`:
  1. Click the green **+** button. Keep all defaults.
  1. For **Name**, enter `tcp-routers`.
  1. From the **Type** dropdown, select **HTTP**.
  1. From the **Method** dropdown, select **GET**.
  1. From the **URL** dropdown, select **/health**.

1. To create a new monitor for `diego-brains`:
  1. Click the green **+** button. Keep all defaults.
  1. For **Name**, enter `diego-brains`.
  1. From the **Type** dropdown, select **TCP**.

These monitors are selected during the next step when pools are created. A pool and a monitor are matched 1:1.

### <a id="pools"></a> Step 2.6: Create Pools of Multi-Element <%= vars.ops_manager %> Targets

This procedure describes creating the pools of resources that ESG load-balances to: the Gorouter, TCP router, and Diego Brain jobs deployed by BOSH Director. If the IP addresses specified in the configuration do not exactly match the IP addresses reserved or used for the resources, then the pool does not effectively load-balance.

#### <a id="http_router_pools"></a> Step 2.6a: Create Pool for `http-routers`

To create a pool for `http-routers`:

1. Select **Load Balancer**.

1. Select **Pools**.

1. Click the green **+** button to create a new pool.

1. Click the pencil icon to edit the pool.

1. For **Name**, enter `http-routers`.

1. From the **Algorithm** dropdown, select **ROUND-ROBIN**.

1. From the **Monitors** dropdown, select **http-routers**.

1. Under **Members**, click the green **+** button to enter all of the IP addresses reserved for the Gorouters into this pool. If you reserved more addresses than you have Gorouters, enter the addresses anyway. The load balancer ignores the missing resources as "down".
    <p class="note"><strong>Note:</strong> If your deployment matches the <a href="./vsphere_ref_arch.html">vSphere Reference Architecture</a>, these IP addresses are in the 192.168.20.0/22 address space.</p>

1. Enter the ports the Gorouters use:
  1. For **Port**, enter `80`.
      <p class='note'><strong>Note:</strong> ESG assumes that internal traffic from the ESG load balancer to the Gorouters is trusted because it is on a VXLAN secured within NSX. If using encrypted TLS traffic to the Gorouter inside the VXLAN, enter <code>443</code> for <strong>Port</strong>.</p>
  1. For **Monitor Port**, enter `8080`.

<%= image_tag('images/vsphere-edit-pool-bordered.png', :alt => "'Edit Pool' screen shows Name with 'http-routers'. Members table has several rows with Monitor port of 8080.") %>

#### <a id="tcp_router_pools"></a> Step 2.6b: Create Pool for `tcp-routers`

To create a pool for `tcp-routers`:

1. Select **Load Balancer**.

1. Select **Pools**.

1. Click the green **+** button to create a new pool.

1. Click the pencil icon to to edit the pool.

1. For **Name**, enter `tcp-routers`.

1. From the **Algorithm** dropdown, select **ROUND-ROBIN**.

1. From the **Monitors** dropdown, select **tcp-routers**.

1. Under **Members**, click the green **+** button to enter all of the IP addresses reserved for the TCP routers into this pool. If you reserved more addresses than you have Gorouters, enter the addresses anyway. The load balancer ignores the missing resources as "down".
    <p class="note"><strong>Note:</strong> If your deployment matches the <a href="./vsphere_ref_arch.html">vSphere Reference Architecture</a>, these IP addresses are in the 192.168.20.0/22 address space.</p>

1. Enter the ports the TCP routers use:
  1. Leave **Port** empty.
  1. For **Monitor Port**, enter `80`.

#### <a id="diego_brain_pools"></a> Step 2.6c: Create Pool for `diego-brains`

To create a pool for `diego-brains`:

1. Select **Load Balancer**.

1. Select **Pools**.

1. Click the green **+** button to create a new pool.

1. Click the pencil icon to to edit the pool.

1. For **Name**, enter `diego-brains`.

1. From the **Algorithm** dropdown, select **ROUND-ROBIN**.

1. From the **Monitors** dropdown, select **diego-brains**.

1. Under **Members**, click the green **+** button to enter all of the IP addresses reserved for the Diego Brains into this pool. If you reserved more addresses than you have Gorouters, enter the addresses anyway. The load balancer ignores the missing resources as "down".
    <p class="note"><strong>Note:</strong> If your deployment matches the <a href="vsphere_ref_arch.html">vSphere Reference Architecture</a>, these IP addresses are in the 192.168.20.0/22 address space.</p>

1. Enter the ports the Diego Brains use:
  1. For **Port**, enter `2222`.
  1. For **Monitor Port**, enter `2222`.

### <a id="create_virtual_servers"></a> Step 2.7: Create Virtual Servers

A The Virtual Server is the Virtual IP (VIP) that the load balancer uses to represent the pool of Gorouters to the outside world. A The Virtual Server also links the Application Policy, Application Rules, and back end pools to provide <%= vars.app_runtime_abbr %> load balancing services. The Virtual Server is the interface that the load balancer balances **from**. You create three Virtual Servers.

To create the Virtual Servers:

1. Select **Load Balancer**.

1. Select **Virtual Servers**.

1. Select an IP address from the available routable address space allocated to the ESG. For information about reserved IP addresses, see [General Overview](#overview).

1. To create the `GoRtr-HTTP` Virtual Server:
  1. Click the green **+** button.
  1. Click the pencil icon to to edit the Virtual Server.
  1. From the **Application Profile** dropdown, select **<%= vars.platform_code %>-HTTP**.
  1. For **Name**, enter `GoRtr-HTTP`.
	1. For **IP Address**, click **Select IP Address** to select the IP address to use as a VIP on the uplink interface.
	1. From the **Protocol** dropdown, select **HTTP**.
  1. For **Port**, enter `80`.
	1. From the **Default Pool** dropdown, select **http-routers**. This connects this VIP to the pool of resources being load-balanced to.
	1. (Optional)	If you want to configure a connection limit, enter an integer in **Connection Limit**.
  1. (Optional)	If you want to configure a connection rate limit, enter an integer in **Connection Rate Limit**.
	1. Select the **Advanced** tab.
  1. Click the green **+** button to add the `option httplog`, `reqadd X-Forwarded-Proto:\ http`, and `reqadd X-Forwarded-Proto:\ https` Application Rules to this Virtual Server.
    <p class="note"><strong>Note:</strong> Ensure that you match the protocol rule <code>VIP- HTTP</code> to the <code>HTTP</code> protocol and the protocol rule <code>HTTPS</code> to the <code>HTTPS</code> protocol.</p>

1. To create the `GoRtr-HTTPS` Virtual Server:
  1. Click the green **+** button.
  1. Click the pencil icon to to edit the Virtual Server.
  1. From the **Application Profile** dropdown, select **<%= vars.platform_code %>-HTTPS**.
  1. For **Name**, enter `GoRtr-HTTPS`.
  1. For **IP Address**, click **Select IP Address** to select the IP address to use as a VIP on the uplink interface.
  1. From the **Protocol** dropdown, select **HTTPS**.
  1. For **Port**, enter `443`.
  1. From the **Default Pool** dropdown, select **https-routers**. This connects this VIP to the pool of resources being load-balanced to.
  1. (Optional)	If you want to configure a connection limit, enter an integer in **Connection Limit**.
  1. (Optional)	If you want to configure a connection rate limit, enter an integer in **Connection Rate Limit**.
  1. Select the **Advanced** tab.
  1. Click the green **+** button to add the `option httplog`, `reqadd X-Forwarded-Proto:\ http`, and `reqadd X-Forwarded-Proto:\ https` Application Rules to this Virtual Server.
    <p class="note"><strong>Note:</strong> Ensure that you match the protocol rule <code>VIP- HTTP</code> to the <code>HTTP</code> protocol and the protocol rule <code>HTTPS</code> to the <code>HTTPS</code> protocol.</p>

1. To create the `TCPRtrs` Virtual Server:
  1. Click the green **+** button.
  1. Click the pencil icon to to edit the Virtual Server.
  1. From the **Application Profile** dropdown, select **<%= vars.platform_code %>-TCP**.
  1. For **Name**, enter `TCPRtrs`.
  1. For **IP Address**, click **Select IP Address** to select the IP address to use as a VIP on the uplink interface.
  1. From the **Protocol** dropdown, select **TCP**.
  1. For **Port**, enter `5000`.
  1. From the **Default Pool** dropdown, select **tcp-routers**. This connects this VIP to the pool of resources being load-balanced to.
  1. (Optional)	If you want to configure a connection limit, enter an integer in **Connection Limit**.
  1. (Optional)	If you want to configure a connection rate limit, enter an integer in **Connection Rate Limit**.
    <%= image_tag('images/vsphere-tcprouter-vip.png', :alt => "Modal 'Edit Virtual Server' on 'General' tab. Includes several fields. 'Connection Rate Limit' is a text field.") %>

1. To create the `SSH-DiegoBrains` Virtual Server:
  1. Click the green **+** button.
  1. Click the pencil icon to to edit the Virtual Server.
  1. From the **Application Profile** dropdown, select **<%= vars.platform_code %>-HTTPS**.
  1. For **Name**, enter `TCPRtrs`.
  1. For **IP Address**, click **Select IP Address**. If you want to use this IP address for SSH access to apps, select the same IP address to use as a VIP on the uplink interface. If not, select a different IP address to use as the VIP.
  1. From the **Protocol** dropdown, select **TCP**.
  1. For **Port**, enter `2222`.
  1. From the **Default Pool** dropdown, select **diego-brains**. This connects this VIP to the pool of resources being load-balanced to.
  1. (Optional)	If you want to configure a connection limit, enter an integer in **Connection Limit**.
  1. (Optional)	If you want to configure a connection rate limit, enter an integer in **Connection Rate Limit**.
    <%= image_tag('images/vsphere-vip-3.png', :alt => "Modal 'New Virtual Server' has same fields as 'Edit Virtual Server' modal.") %>


## <a id="nat_snat"></a> Step 3: Configure NAT/SNAT

The ESG obfuscates the installation through network translation. The installation is placed entirely on non-routable RFC-1918 network address space, so you must translate routable IP addresses to non-routable IP addresses to make connections.

<p class="note"><strong>Note:</strong> Correct NAT/SNAT configuration is required for the installation to function as expected.</p>

To translate routable IP addresses to non-routable IP addresses, see the table below:

<table class="nice" style="table-layout: fixed">
  <tr>
    <th>Action</th>
    <th>Applied on Interface</th>
    <th>Original IP</th>
    <th>Original/<br>Translated Port</th>
    <th>Translated IP</th>
    <th>Protocol</th>
    <th>Description</th>
  </tr>
  <tr>
    <td>SNAT</td>
    <td>Uplink</td>
    <td>192.168.0.0<br>/16</td>
    <td>Any</td>
    <td>Any</td>
    <td>PCF-IP</td>
    <td>All Nets Egress</td>
  </tr>
  <tr>
    <td>DNAT</td>
    <td>Uplink</td>
    <td>OPS-MANAGER-IP</td>
    <td>Any</td>
    <td>192.168.10<br>.OpsMgr </td>
    <td>TCP</td>
    <td>OpsMgr Mask for external use</td>
  </tr>
  <tr>
    <td>SNAT</td>
    <td>Infra</td>
    <td>192.168.10<br>.OpsMgr</td>
    <td>Any</td>
    <td>OPS-MANAGER-IP</td>
    <td>TCP</td>
    <td>OpsMgr Mask for internal use</td>
  </tr>
  <tr>
    <td>DNAT</td>
    <td>Infra</td>
    <td>OPS-MANAGER-IP</td>
    <td>Any</td>
    <td>192.168.10.OpsMgr</td>
    <td>TCP</td>
    <td>OpsMgr Mask for internal use</td>
  </tr>
</table>

<p class="note"><strong>Note:</strong> The NAT/SNAT on the <code>infra</code> network in this table is an example of an optional <strong>Hairpin NAT</strong> rule to allow VMs within the <strong>Infrastructure</strong> network to access the <%= vars.ops_manager %> API. This is because the <%= vars.ops_manager %> hostname and the API HTTPS endpoint are registered to the <%= vars.ops_manager %> VM external IP address. A pair of Hairpin NAT rules are necessary on <strong>each</strong> internal network interface that requires API access to <%= vars.ops_manager %>. You should create these rules only if the network must access the <%= vars.ops_manager %> API.</p>

NAT/SNAT functionality is not required if routable IP address space is used on the Tenant Side of the ESG. At that point, the ESG simply performs routing between the address segments.

<p class="note"><strong>Note:</strong> NSX generates a number of DNAT rules based on load balancing configs. You can safely ignore these.</p>


## <a id="notes"></a> Additional Notes

The ESG also supports scenarios where Private RFC subnets and NAT are not utilized for **Deployment** or **Infrastructure** networks, and the guidance in this topic can be modified to meet those scenarios.

Additionally, the ESG supports up to 10 Interfaces allowing for more Uplink options if necessary.

This topic describes using Private RFC-1918 subnets with deployment networks because they are commonly used. ESG devices are capable of leveraging ECMP, OSPF, BGP, and IS-IS to handle dynamic routing of customer and public L3 IP space. That design is out of scope for this topic, but is supported by VMware NSX and <%= vars.ops_manager %>.
